---
title: 'RvXmBlendNet: A Multi-architecture Hybrid Model for Improved Skin Cancer Detection'
tags:
- journal
- 
links:
  - icon: doi
    icon_pack: fab
    name: DOI
    url: "https://doi.org/10.1007/s44230-024-00083-1"
  - icon:
    icon_pack: fab
    name: URL
    url: "https://link.springer.com/article/10.1007/s44230-024-00083-1"

---

<p align="center">
<img src="https://github.com/thlavlu/Publications/blob/main/test.jpg"/>
</p>
<strong>Abstract: </strong>
<div style="text-align: justify">Skin cancer, one of the most dangerous cancers, poses a significant global threat. While early detection can substantially improve survival rates, traditional dermatologists often face challenges in accurate diagnosis, leading to delays in treatment and avoidable fatalities. Deep learning models like CNN and transfer learning have enhanced diagnosis from dermoscopic images, providing precise and timely detection. However, despite the progress made with hybrid models, many existing approaches still face challenges, such as limited generalization across diverse datasets, vulnerability to overfitting, and difficulty in capturing complex patterns. As a result, there is a growing need for more robust and effective hybrid models that integrate multiple architectures and advanced mechanisms to address these challenges. Therefore, this study aims to introduce a novel multi-architecture hybrid deep learning model called "RvXmBlendNet," which combines the strengths of four individual models: ResNet50 (R), VGG19 (v), Xception (X), and MobileNet (m), followed by "BlendNet" to signify their fusion into a unified architecture. The integration of these models is achieved through a synergistic combination of architectures, incorporating self-attention mechanisms using attention layers and adaptive content blocks. This study used the HAM10000 dataset to refine dermoscopic image preprocessing and enhance deep learning model accuracy. Techniques like OpenCV-based hair removal, minâ€“max scaling, and adaptive histogram equalization were employed to improve image quality and feature extraction. A comparative study between the proposed hybrid "RvXmBlendNet" and individual models (CNN, ResNet50, VGG19, Xception, and MobileNet) demonstrated that "RvXmBlendNet" achieved the highest accuracy of 98.26%, surpassing other models. These results suggest that the system can facilitate earlier interventions, improve patient outcomes, and potentially lower healthcare costs by reducing the need for invasive diagnostic procedures.</div>